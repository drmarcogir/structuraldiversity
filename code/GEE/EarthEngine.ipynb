{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40yXzubBjM7P"
   },
   "source": [
    "### **Extract GEDI, Sentinel 1 and Sentinel 2 data for dataset associated with manuscript \"A dataset on the structural diversity of European forests\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChMLuANwjXo6"
   },
   "source": [
    "  <span style=\"color:red\">   Import packages</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UX9KmrMLjM7T",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize()\n",
    "ee.Initialize(project='XXXX') # need to specify a google cloud project here!\n",
    "import geemap\n",
    "Map = geemap.Map()\n",
    "from IPython.display import JSON\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCf0RTKFjM7U"
   },
   "source": [
    "<span style=\"color:red\">  Functions </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bXoPJstijM7U",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter using quality criteria\n",
    "def gedi_qa(img):\n",
    "    # Check for quality flag\n",
    "    quality = img.select('quality_flag').eq(1)\n",
    "\n",
    "    # Check if it's night\n",
    "    night = img.select('solar_elevation').lte(0)\n",
    "\n",
    "    # Check for no degradation\n",
    "    degrade = img.select('degrade_flag').eq(0)\n",
    "\n",
    "    # Check for low urban proportion\n",
    "    urban = img.select('urban_proportion').lte(5)\n",
    "\n",
    "    # Check for no water persistence\n",
    "    water = img.select('landsat_water_persistence').eq(0)\n",
    "\n",
    "    # Check for significant tree cover\n",
    "    forest = img.select('landsat_treecover').gt(10)\n",
    "\n",
    "    # Check for reasonable RH98 values\n",
    "    rh98_70 = img.select(['rh98']).lte(100)\n",
    "\n",
    "    # Check if it's leaf-on season\n",
    "    leafon = img.select('leaf_off_flag').eq(0)\n",
    "\n",
    "    # Check for detected modes\n",
    "    detectmodes = img.select('num_detectedmodes').gt(0)\n",
    "\n",
    "    # Check for surface flag\n",
    "    surface = img.select('surface_flag').gt(0)\n",
    "\n",
    "    # Check for minimum sensitivity\n",
    "    sensitivitymin = img.select('sensitivity').gte(0.95)\n",
    "\n",
    "    # Apply all masks\n",
    "    return (img.mask(quality)\n",
    "            .updateMask(night)\n",
    "            .updateMask(degrade)\n",
    "            .updateMask(water)\n",
    "            .updateMask(urban)\n",
    "            .updateMask(forest)\n",
    "            .updateMask(slope.lt(20))\n",
    "            .updateMask(rh98_70)\n",
    "            .updateMask(leafon)\n",
    "            .updateMask(detectmodes)\n",
    "            .updateMask(surface)\n",
    "            .updateMask(sensitivitymin))\n",
    "\n",
    "\n",
    "# Terrain correction\n",
    "# Implementation by Andreas Vollrath (ESA), inspired by Johannes Reiche (Wageningen)\n",
    "def terrainCorrection(image):\n",
    "    imgGeom = image.geometry()\n",
    "    srtm = ee.Image('USGS/SRTMGL1_003').clip(imgGeom)  # 30m SRTM\n",
    "    sigma0Pow = ee.Image.constant(10).pow(image.divide(10.0))\n",
    "\n",
    "    # Radar geometry (2.1.1)\n",
    "    theta_i = image.select('angle')\n",
    "    phi_i = (ee.Terrain.aspect(theta_i)\n",
    "             .reduceRegion(ee.Reducer.mean(), theta_i.get('system:footprint'), 1000)\n",
    "             .get('aspect'))\n",
    "\n",
    "    # Terrain geometry (2.1.2)\n",
    "    alpha_s = ee.Terrain.slope(srtm).select('slope')\n",
    "    phi_s = ee.Terrain.aspect(srtm).select('aspect')\n",
    "\n",
    "    # Model geometry (2.1.3)\n",
    "    phi_r = ee.Image.constant(phi_i).subtract(phi_s)\n",
    "\n",
    "    # Convert all to radians\n",
    "    phi_rRad = phi_r.multiply(math.pi / 180)\n",
    "    alpha_sRad = alpha_s.multiply(math.pi / 180)\n",
    "    theta_iRad = theta_i.multiply(math.pi / 180)\n",
    "    ninetyRad = ee.Image.constant(90).multiply(math.pi / 180)\n",
    "\n",
    "    # Slope steepness in range (eq. 2)\n",
    "    alpha_r = alpha_sRad.tan().multiply(phi_rRad.cos()).atan()\n",
    "\n",
    "    # Slope steepness in azimuth (eq. 3)\n",
    "    alpha_az = alpha_sRad.tan().multiply(phi_rRad.sin()).atan()\n",
    "\n",
    "    # Local incidence angle (eq. 4)\n",
    "    theta_lia = alpha_az.cos().multiply(theta_iRad.subtract(alpha_r).cos()).acos()\n",
    "    theta_liaDeg = theta_lia.multiply(180 / math.pi)\n",
    "\n",
    "    # Gamma_nought_flat (2.2)\n",
    "    gamma0 = sigma0Pow.divide(theta_iRad.cos())\n",
    "    gamma0dB = ee.Image.constant(10).multiply(gamma0.log10())\n",
    "    ratio_1 = gamma0dB.select('VV').subtract(gamma0dB.select('VH'))\n",
    "\n",
    "    # Volumetric Model\n",
    "    nominator = (ninetyRad.subtract(theta_iRad).add(alpha_r)).tan()\n",
    "    denominator = (ninetyRad.subtract(theta_iRad)).tan()\n",
    "    volModel = nominator.divide(denominator).abs()\n",
    "\n",
    "    # Apply model\n",
    "    gamma0_Volume = gamma0.divide(volModel)\n",
    "    gamma0_VolumeDB = ee.Image.constant(10).multiply(gamma0_Volume.log10())\n",
    "\n",
    "    # Layover/shadow mask\n",
    "    alpha_rDeg = alpha_r.multiply(180 / math.pi)\n",
    "    layover = alpha_rDeg.lt(theta_i)\n",
    "\n",
    "    shadow = theta_liaDeg.lt(85)\n",
    "\n",
    "    # Calculate the ratio for RGB vis\n",
    "    ratio = gamma0_VolumeDB.select('VV').subtract(gamma0_VolumeDB.select('VH'))\n",
    "\n",
    "    output = (gamma0_VolumeDB\n",
    "              .addBands(ratio)\n",
    "              .addBands(alpha_r)\n",
    "              .addBands(phi_s)\n",
    "              .addBands(theta_iRad)\n",
    "              .addBands(layover)\n",
    "              .addBands(shadow)\n",
    "              .addBands(gamma0dB)\n",
    "              .addBands(ratio_1))\n",
    "\n",
    "    return image.addBands(output.select(['VV', 'VH'], ['VV', 'VH']), None, True)\n",
    "\n",
    "# Convert power to decibels\n",
    "def powerToDb(img):\n",
    "    # Multiply the logarithm base 10 of the image by 10 to convert to decibels\n",
    "    return ee.Image(10).multiply(img.log10())\n",
    "\n",
    "\n",
    "# Convert decibels to power\n",
    "def dbToPower(img):\n",
    "    # Raise 10 to the power of the image divided by 10 to convert to power\n",
    "    return ee.Image(10).pow(img.divide(10))\n",
    "\n",
    "\n",
    "# Convert image to decibels\n",
    "def toDB(img):\n",
    "    # Convert the image to decibels by taking the logarithm base 10 and multiplying by 10\n",
    "    return ee.Image(img).log10().multiply(10.0)\n",
    "\n",
    "\n",
    "# Convert image to natural units\n",
    "def toNatural(img):\n",
    "    # Convert decibels to natural units and preserve additional bands and properties\n",
    "    return (\n",
    "        ee.Image(10.0).pow(img.select('..').divide(10.0))  # Convert decibels to natural units\n",
    "        .addBands(img.select('angle', 'DOY', 'Year'))  # Add angle, DOY, and Year bands\n",
    "        .copyProperties(img, ['system:time_start'])  # Copy properties from the original image\n",
    "    )\n",
    "\n",
    "\n",
    "# Remove edges for VH band\n",
    "def maskEdgeVH(img):\n",
    "    # Create a mask to remove edges based on the VH band\n",
    "    mask = (\n",
    "        img.select(['VH'])\n",
    "        .unitScale(-25, 5)  # Scale the VH band to the range [0, 255]\n",
    "        .multiply(255)\n",
    "        .toByte()\n",
    "        .connectedComponents(ee.Kernel.rectangle(1, 1), 250)  # Identify connected components\n",
    "    )\n",
    "    # Update the mask of the image with the created mask and preserve properties\n",
    "    return img.updateMask(mask.select(['VH'])).copyProperties(img, ['system:time_start'])\n",
    "\n",
    "\n",
    "# Remove stripes for VH band\n",
    "def stripeMaskVH(im):\n",
    "    # Create a mask to remove stripes based on the VH band\n",
    "    # VH backscatter of stripes is often less than -25dB\n",
    "    mask = ee.Image(0).where(im.select(['VH']).lte(-25), 1).Not()\n",
    "    # Update the mask of the image with the created mask and preserve properties\n",
    "    return im.updateMask(mask).copyProperties(im, ['system:time_start'])\n",
    "\n",
    "\n",
    "# Remove edges for VV band\n",
    "def maskEdgeVV(img):\n",
    "    # Create a mask to remove edges based on the VV band\n",
    "    mask = (\n",
    "        img.select(['VV'])\n",
    "        .unitScale(-25, 5)  # Scale the VV band to the range [0, 255]\n",
    "        .multiply(255)\n",
    "        .toByte()\n",
    "        .connectedComponents(ee.Kernel.rectangle(1, 1), 250)  # Identify connected components\n",
    "    )\n",
    "    # Update the mask of the image with the created mask and preserve properties\n",
    "    return img.updateMask(mask.select(['VV'])).copyProperties(img, ['system:time_start'])\n",
    "\n",
    "\n",
    "# Remove stripes for VV band\n",
    "def stripeMaskVV(im):\n",
    "    # Create a mask to remove stripes based on the VV band\n",
    "    # VV backscatter of stripes is often less than -25dB\n",
    "    mask = ee.Image(0).where(im.select(['VV']).lte(-25), 1).Not()\n",
    "    # Update the mask of the image with the created mask and preserve properties\n",
    "    return im.updateMask(mask).copyProperties(im, ['system:time_start'])\n",
    "\n",
    "\n",
    "# Mask cloud and shadows for Sentinel 2\n",
    "def maskCloudAndShadowsSR(image):\n",
    "    # Select cloud probability band\n",
    "    cloudProb = image.select('MSK_CLDPRB')\n",
    "\n",
    "    # Get snow probability band\n",
    "    snowProb = image.select('MSK_SNWPRB')\n",
    "\n",
    "    # Select threshold for cloud probability\n",
    "    cloud = cloudProb.lt(5)\n",
    "\n",
    "    # Scene Classification Map - provides pixel classification map\n",
    "    scl = image.select('SCL')\n",
    "\n",
    "    # Create mask for scl shadows\n",
    "    shadow = scl.eq(3)\n",
    "\n",
    "    # Create mask for scl cirrus\n",
    "    cirrus = scl.eq(10)\n",
    "\n",
    "    # Create mask for snow\n",
    "    snow = snowProb.lt(5)\n",
    "\n",
    "    # Combine filters into final mask\n",
    "    mask = (cloud.And(snow)).And(cirrus.neq(1)).And(shadow.neq(1))\n",
    "\n",
    "    # Return final image with updated mask\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "\n",
    "# Calculate image percentiles\n",
    "def imgperc(ind):\n",
    "    # Mask for values > 0 for both NDVI and the spectral index\n",
    "    res = (spindices.updateMask(spindices.select('ndvi').gt(0))\n",
    "           .updateMask(spindices.select(ind).gt(0))\n",
    "           .select(ind)\n",
    "           .reduceRegion(reducer=ee.Reducer.percentile([1, 99]),\n",
    "                         geometry=glb,\n",
    "                         scale=1000,\n",
    "                         maxPixels=1e13,\n",
    "                         tileScale=4))\n",
    "    # Get values from server side\n",
    "    return res.getInfo()\n",
    "\n",
    "\n",
    "# Add NDVI band to the image\n",
    "def addNDVI(img):\n",
    "    ndvi = img.normalizedDifference(['B8', 'B4']).rename(\"ndvi\")\n",
    "    return img.addBands(ndvi).addBands(\n",
    "        ee.Image.constant(ee.Number.parse(img.date().format(\"D\"))).rename('DOY').float()\n",
    "    )\n",
    "\n",
    "\n",
    "# Remove DOY for max period\n",
    "def removedoy_max(img):\n",
    "    imageDOY = img.select('DOY').where(img.select('Year').eq(2020), img.select('DOY').add(365))\n",
    "    imageDOY = imageDOY.select('DOY').where(img.select('Year').eq(2021), imageDOY.select('DOY').add(731))\n",
    "    imageDOY = imageDOY.addBands(img.select('constant', 'angle', 'Year'))\n",
    "    return imageDOY.updateMask(imageDOY.select('DOY').gte(DOY_Before)).updateMask(imageDOY.select('DOY').lte(DOY_After))\n",
    "\n",
    "\n",
    "# Remove DOY for pre period\n",
    "def removedoy_pre(img):\n",
    "    imageDOY = img.select('DOY').where(img.select('Year').eq(2020), img.select('DOY').add(365))\n",
    "    imageDOY = imageDOY.select('DOY').where(img.select('Year').eq(2021), imageDOY.select('DOY').add(731))\n",
    "    imageDOY = imageDOY.addBands(img.select('constant', 'angle', 'Year'))\n",
    "    return imageDOY.updateMask(imageDOY.select('DOY').gte(DOY_pre)).updateMask(imageDOY.select('DOY').lte(DOY_Before))\n",
    "\n",
    "\n",
    "# Remove DOY for post period\n",
    "def removedoy_post(img):\n",
    "    imageDOY = img.select('DOY').where(img.select('Year').eq(2020), img.select('DOY').add(365))\n",
    "    imageDOY = imageDOY.select('DOY').where(img.select('Year').eq(2021), imageDOY.select('DOY').add(731))\n",
    "    imageDOY = imageDOY.addBands(img.select('constant', 'angle', 'Year'))\n",
    "    return imageDOY.updateMask(imageDOY.select('DOY').gte(DOY_After)).updateMask(imageDOY.select('DOY').lte(DOY_post))\n",
    "\n",
    "\n",
    "# Add date bands to the image\n",
    "def addDates(img):\n",
    "    return (\n",
    "        img.addBands(ee.Image.constant(ee.Number.parse(img.date().format(\"D\"))).rename('DOY').float())\n",
    "        .addBands(ee.Image.constant(ee.Number.parse(img.date().format(\"Y\"))).rename('Year').float())\n",
    "    )\n",
    "\n",
    "\n",
    "# Remove DOY for growing period\n",
    "def removedoygrowing(img):\n",
    "    imageDOY = img.select('DOY').where(img.select('Year').eq(2020), img.select('DOY').add(365))\n",
    "    imageDOY = imageDOY.select('DOY').where(img.select('Year').eq(2021), imageDOY.select('DOY').add(731))\n",
    "    imageDOY = imageDOY.addBands(img.select('constant', 'angle', 'Year'))\n",
    "    return imageDOY.updateMask(imageDOY.select('DOY').gte(DOY_pre)).updateMask(imageDOY.select('DOY').lte(DOY_post))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8ZZ9-E6jM7W"
   },
   "source": [
    "<span style=\"color:red\">  Load collections </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMt_ENQVjM7W",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Export grid\n",
    "globalgrid = ee.FeatureCollection('users/guidolavespa2511/Cell2DegSq') \n",
    "\n",
    "# bounding box for Global\n",
    "glb = globalgrid.geometry().bounds()\n",
    "\n",
    "# Hansen forest cover dataset\n",
    "gfc = ee.Image(\"UMD/hansen/global_forest_change_2022_v1_10\")\n",
    "\n",
    "# GEDI data\n",
    "# 2A metrics (heights)\n",
    "gedi_A = (ee.ImageCollection(\"LARSE/GEDI/GEDI02_A_002_MONTHLY\")\n",
    "                                .filterBounds(glb))\n",
    "\n",
    "# 2B metrics (pai, fhd)\n",
    "gedi_B = (ee.ImageCollection(\"LARSE/GEDI/GEDI02_B_002_MONTHLY\")\n",
    "                                .filterBounds(glb))\n",
    "\n",
    "# digital elevation model (dem)\n",
    "dem = ee.Image('USGS/SRTMGL1_003').select('elevation')\n",
    "\n",
    "# calculate slope from dem\n",
    "slope = ee.Terrain.slope(dem)\n",
    "\n",
    "# sentinel 1: PLEASE NOTE THAT THIS COLLECTION IS FILTERED EARLY IN THE WORFLOW USING Global AS A BOUNDING BOX!\n",
    "s1 = ee.ImageCollection('COPERNICUS/S1_GRD').filterBounds(glb)\n",
    "\n",
    "# sentinel 2: PLEASE NOTE THAT THIS COLLECTION IS FILTERED EARLY IN THE WORFLOW USING Global AS A BOUNDING BOX!\n",
    "s2 = ee.ImageCollection('COPERNICUS/S2_SR').filterBounds(glb)\n",
    "\n",
    "# alos palsar\n",
    "alos = (ee.ImageCollection('JAXA/ALOS/PALSAR/YEARLY/SAR')\n",
    "                  .filter(ee.Filter.date('2019-01-01', '2020-12-31')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hk9VOnrejM7W",
    "tags": []
   },
   "source": [
    "<span style=\"color:red\">  GEDI data pre-processing </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5WiMWlxjM7X",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Heights: filter for quality criteria\n",
    "gedi_A_clean = (gedi_A\n",
    "                     #.map(gedi_sel)\n",
    "                     .map(gedi_qa)\n",
    "                     .select(['rh.*']).qualityMosaic('rh98'))\n",
    "                     #.map(filter_rh25)\n",
    "                     #.select(['rh.*','sensitivity']).qualityMosaic('rh98'))\n",
    "\n",
    "# Aggreate Level 2B metrics\n",
    "foliage = (gedi_B.qualityMosaic('fhd_normal')\n",
    "                 #.updateMask(gedi_2020_B.qualityMosaic('fhd_normal'))\n",
    "                 .select(['fhd_normal','pai','l2b_quality_flag','degrade_flag','cover']))\n",
    "\n",
    "# --------- Internal variability metrics from L2A dataset\n",
    "# Including Negative + Positive values\n",
    "# skewness\n",
    "skew = gedi_A_clean.reduce(ee.Reducer.skew()).rename('skew_negativevalues')\n",
    "\n",
    "# kurtosis\n",
    "kurt = gedi_A_clean.reduce(ee.Reducer.kurtosis()).rename('kurt_negativevalues')\n",
    "\n",
    "# standard deviation\n",
    "sd = gedi_A_clean.reduce(ee.Reducer.stdDev()).rename('sd_negativevalues')\n",
    "\n",
    "# mean\n",
    "mu = gedi_A_clean.reduce(ee.Reducer.mean()).rename('mu_negativevalues')\n",
    "\n",
    "# cv\n",
    "cv = sd.divide(mu).rename('cv_negativevalues')\n",
    "\n",
    "# Including only Positive values\n",
    "# convert to array image\n",
    "arr = (gedi_A_clean\n",
    "        .toArray())\n",
    "\n",
    "# trick to solve the problem of pixels with certain bands masked\n",
    "dummyImage = ee.Image(-3278).toArray()\n",
    "\n",
    "arr1 = (arr.arrayMask(arr.gt(0)))\n",
    "\n",
    "l = arr1.arrayLength(0)\n",
    "\n",
    "arr2 = arr1.where(l.eq(0),dummyImage)\n",
    "\n",
    "# mean\n",
    "mu1 =  (arr2.arrayReduce(reducer = ee.Reducer.mean(),\n",
    "                     axes = [0])\n",
    "        .arrayFlatten([['0']])\n",
    "        .rename('mean'))\n",
    "\n",
    "# standard deviation\n",
    "sd1 = (arr2.arrayReduce(reducer = ee.Reducer.stdDev(),\n",
    "                     axes = [0])\n",
    "        .arrayFlatten([['0']])\n",
    "        .rename('sd'))\n",
    "\n",
    "# coefficient of variation\n",
    "cv1 = sd1.divide(mu1).rename('cv')\n",
    "\n",
    "# skewness\n",
    "skew1 = (arr2.arrayReduce(reducer = ee.Reducer.skew(),\n",
    "                     axes = [0])\n",
    "        .arrayFlatten([['0']])).rename('skew')\n",
    "\n",
    "\n",
    "# kurtosis\n",
    "kurt1 = (arr2.arrayReduce(reducer = ee.Reducer.kurtosis(),\n",
    "                     axes = [0])\n",
    "        .arrayFlatten([['0']])).rename('kurt')\n",
    "\n",
    "\n",
    "#---------- Put everything together\n",
    "\n",
    "# Heights: select relevant bands\n",
    "#heights = (gedi_A_clean.select(['rh25','rh50','rh75','rh98','sensitivity']))\n",
    "heights = (gedi_A_clean.select(['rh25','rh50','rh75','rh98']))\n",
    "\n",
    "\n",
    "# Combine everything together\n",
    "strmetrs = heights.addBands(foliage).addBands(skew).addBands(kurt).addBands(sd).addBands(mu).addBands(cv).addBands(skew1).addBands(kurt1).addBands(sd1).addBands(mu1).addBands(cv1)#.addBands(pavd_cv)\n",
    "\n",
    "# Filter for quality criteria based on level 2B metrics as well as rh98 > 5\n",
    "strmetrs = (strmetrs\n",
    "                .updateMask(strmetrs.select('l2b_quality_flag').eq(1))\n",
    "                .updateMask(strmetrs.select('degrade_flag').eq(0))\n",
    "                .updateMask(strmetrs.select('rh50').gt(0))\n",
    "                .updateMask(strmetrs.select('cover').gt(0.1))\n",
    "                .select(['rh25','rh50','rh75','rh98','fhd_normal','pai','cover','skew_negativevalues','kurt_negativevalues','sd_negativevalues',\n",
    "                         'mu_negativevalues','cv_negativevalues','skew','kurt','sd','mean','cv']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEupXrZOjM7Y"
   },
   "source": [
    "<span style=\"color:red\"> Hansen data pre-processing <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1OGKtfvDjM7Y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get tree cover for the year 2000\n",
    "treecover = gfc.select(['treecover2000'])\n",
    "\n",
    "# get tree cover loss band\n",
    "loss = gfc.select(['loss'])\n",
    "\n",
    "# only pixels with a tree cover greater than or equal to 30%\n",
    "treecover30p = treecover.updateMask(treecover.gte(30))\n",
    "\n",
    "# filter out pixels where there was loss\n",
    "tcovernoloss = treecover30p.updateMask(loss.eq(0))\n",
    "\n",
    "# self mask tree cover layer\n",
    "sf_mask = treecover.updateMask(loss.eq(0)).gte(30).selfMask()\n",
    "\n",
    "# calculated count of pixels for different forest\n",
    "patch_count = sf_mask.connectedPixelCount(maxSize = 1024,eightConnected =  False)\n",
    "\n",
    "# filter out small patches from cover dataset\n",
    "tcovernoloss = tcovernoloss.updateMask(patch_count.gt(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJGHDWWJjM7Y"
   },
   "source": [
    "<span style=\"color:red\">  Sentinel 2 max NDVI This is needed in order to identify the dates when  NDVI reaches it  maximum values\n",
    "<br> It is the baseline for identifying a window that can be defineded as growing season. Note that this only done for\n",
    "the year 2020. <br> This is considered as a central year for the period of interest </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9W7EIgAejM7Z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set start and end dates\n",
    "startYear = 2020\n",
    "endYear = 2021\n",
    "startDate = '2020-01-01'\n",
    "endDate = '2020-12-31'\n",
    "start_date = ee.Date.fromYMD(startYear, 1, 1);\n",
    "end_date   = ee.Date.fromYMD(endYear, 12, 31);\n",
    "\n",
    "# filter by date\n",
    "s2filt = (s2.filterDate(\"2020-01-01\",\"2020-12-31\")\n",
    "         # filter by cloudy pixel percentage\n",
    "         .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 70))\n",
    "         .map(maskCloudAndShadowsSR)\n",
    "          # add NDVI\n",
    "         .map(addNDVI))\n",
    "\n",
    "# create quality mosaic using the ndvi band\n",
    "ndviCollectionMax = (s2filt\n",
    "                    .qualityMosaic('ndvi')\n",
    "                    .set('system:time_start',start_date.millis()))\n",
    "\n",
    "# select only relevant bands\n",
    "YearMaxComposite = ndviCollectionMax.select('ndvi','DOY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qs-mhI_ijM7Z"
   },
   "source": [
    "<span style=\"color:red\">  Sentinel 1 data pre-processing </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhqItcnWjM7Z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Sentinel-1 Collection\n",
    "s1filt =  (s1.filterDate(\"2019-10-15\",\"2021-03-15\")\n",
    "            .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\n",
    "            .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
    "            .filterMetadata('resolution_meters', 'equals' , 10)\n",
    "            .filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING'))\n",
    "            .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "            .map(addDates))\n",
    "\n",
    "# apply terrain correction\n",
    "s1filt1 = s1filt.map(terrainCorrection)\n",
    "\n",
    "# select band, mask edge and destripe (?)\n",
    "s1VH = (s1filt1.select(['VH','angle','DOY','Year'])\n",
    "              .map(maskEdgeVH)\n",
    "              .map(stripeMaskVH)\n",
    "              .map(toNatural))\n",
    "\n",
    "# select band, mask edge and destripe (?)\n",
    "s1VV = (s1filt1.select(['VV','angle','DOY','Year'])\n",
    "              .map(maskEdgeVV)\n",
    "              .map(stripeMaskVV)\n",
    "              .map(toNatural))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEzgP7OFl0UT"
   },
   "source": [
    "##### General settings for creating Sentinel 1 composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DlmJepaalw8i"
   },
   "outputs": [],
   "source": [
    "# create shifts in the day of the YEAR\n",
    "DOY_Max = YearMaxComposite.select('DOY').add(365)\n",
    "DOY_Before = YearMaxComposite.select('DOY').add(365).subtract(30)\n",
    "DOY_After = YearMaxComposite.select('DOY').add(365).add(30)\n",
    "# substract and add 60 days. This is needed for the calculations of bimonthly composites shifted of 2 months from the window of the maximum\n",
    "DOY_pre = DOY_Before.subtract(60)\n",
    "DOY_post = DOY_After.add(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_PQtmvMjM7a"
   },
   "source": [
    "\n",
    "<span style=\"color:red\">  Create Sentinel 1 backscatter growing season averages </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f503NbbNjM7a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create composite for VH band\n",
    "VH_mean_gs = (toDB(s1VH.map(removedoygrowing)\n",
    "               .mean())\n",
    "               .select('constant')\n",
    "               .rename('VH_gs')\n",
    "               .updateMask(tcovernoloss.gt(0)))\n",
    "\n",
    "# create composite for VV band\n",
    "VV_mean_gs = (toDB(s1VV.map(removedoygrowing)\n",
    "               .mean())\n",
    "               .select('constant')\n",
    "               .rename('VV_gs')\n",
    "               .updateMask(tcovernoloss.gt(0)))\n",
    "\n",
    "S1comb_gs = VH_mean_gs.addBands(VV_mean_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzwmxqQijM7a"
   },
   "source": [
    "<span style=\"color:red\">  Create Sentinel 1 backscatter growing season standard deviation </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgmwbmuwjM7a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "VH_std = (s1VH.map(removedoygrowing)\n",
    "     .map(toDB)\n",
    "     .reduce(ee.Reducer.stdDev())\n",
    "     .select('constant_stdDev')\n",
    "     .rename('VH_std')\n",
    "     .updateMask(tcovernoloss.gt(0)))\n",
    "\n",
    "VV_std = (s1VV.map(removedoygrowing)\n",
    "     .map(toDB)\n",
    "     .reduce(ee.Reducer.stdDev())\n",
    "     .select('constant_stdDev')\n",
    "     .rename('VV_std')\n",
    "     .updateMask(tcovernoloss.gt(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZhbi-2_jM7a"
   },
   "source": [
    "<span style=\"color:red\">  Create Sentinel 1 backscatter bimonthly composites. The final result includes 3 composites: <br>\n",
    "i) around the maximum of the growing season ii) two three months before and three months after </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VgPd4YMUjM7b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#---- VV\n",
    "# composite around the maximum (+-30)\n",
    "VV_around_max = (toDB(s1VV.map(removedoy_max).mean())\n",
    "                    .select('constant')\n",
    "                    .rename('VV_max')\n",
    "                    .updateMask(tcovernoloss.gt(0)))\n",
    "\n",
    "# composite 2 months before the maximum - 1 month\n",
    "VV_pre = (toDB(s1VV.map(removedoy_pre).mean())\n",
    "                      .select('constant')\n",
    "                      .rename('VV_pre')\n",
    "                      .updateMask(tcovernoloss.gt(0)))\n",
    "\n",
    "# composite 2 months after the maximum + 1 month\n",
    "VV_post = (toDB(s1VV.map(removedoy_post)\n",
    "                    .mean())\n",
    "                    .select('constant')\n",
    "                    .rename('VV_post')\n",
    "                    .updateMask(tcovernoloss.gt(0)))\n",
    "\n",
    "# create a single multiband image (for VV band)\n",
    "VV_bimon = VV_around_max.addBands(VV_pre).addBands(VV_post)\n",
    "\n",
    "#---- VH\n",
    "# composite around the maximum (+-30)\n",
    "VH_around_max = (toDB(s1VH.map(removedoy_max)\n",
    "                        .mean())\n",
    "                        .select('constant')\n",
    "                        .rename('VH_max')\n",
    "                        .updateMask(tcovernoloss.gt(0)))\n",
    "\n",
    "# composite 2 months before the maximum - 1 month\n",
    "VH_pre = (toDB(s1VH.map(removedoy_pre)\n",
    "                  .mean())\n",
    "                  .select('constant')\n",
    "                  .rename('VH_pre')\n",
    "                  .updateMask(tcovernoloss.gt(0)))\n",
    "\n",
    "# composite 2 months after the maximum + 1 month\n",
    "VH_post = (toDB(s1VH.map(removedoy_post)\n",
    "                   .mean())\n",
    "                   .select('constant')\n",
    "                   .rename('VH_post')\n",
    "                   .updateMask(tcovernoloss.gt(0)))\n",
    "\n",
    "# create a single multiband image (for VH band)\n",
    "VH_bimon = VH_around_max.addBands(VH_pre).addBands(VH_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5r3f4psfjM7b"
   },
   "source": [
    "<span style=\"color:red\">  Average of Sentinel1 backscatter values around a 3 x 3 neighbourhood </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5q_-vZFNjM7b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "S1gs_mean = S1comb_gs.reduceNeighborhood(reducer = ee.Reducer.mean(),\n",
    "                             kernel = ee.Kernel.square(3))\n",
    "\n",
    "VV_bimon_mean = VV_bimon.reduceNeighborhood(reducer = ee.Reducer.mean(),\n",
    "                             kernel = ee.Kernel.square(3))\n",
    "\n",
    "VH_bimon_mean = VH_bimon.reduceNeighborhood(reducer = ee.Reducer.mean(),\n",
    "                             kernel = ee.Kernel.square(3))\n",
    "\n",
    "S1_VV_std_mean = VV_std.reduceNeighborhood(reducer = ee.Reducer.mean(),\n",
    "                             kernel = ee.Kernel.square(3))\n",
    "\n",
    "S1_VH_std_mean = VH_std.reduceNeighborhood(reducer = ee.Reducer.mean(),\n",
    "                             kernel = ee.Kernel.square(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Hd2SDsojM7b",
    "tags": []
   },
   "source": [
    "<span style=\"color:red\">  Sentinel 1 texture metrics (angular second moment, entropy and dissimilarity)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zfjvxMAjM7c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate texture metrics using min and max as inputs\n",
    "glcmVHG = (VH_mean_gs\n",
    "            .abs()\n",
    "            .unitScale(min(VV_percabs),max(VV_percabs))\n",
    "            .multiply(255)\n",
    "            .toByte()\n",
    "            .glcmTexture(size = 3)\n",
    "            .select(['VH_gs_ent','VH_gs_diss','VH_gs_asm']))\n",
    "\n",
    "# calculate texture metrics using min and max as inputs\n",
    "glcmVVG = (VV_mean_gs\n",
    "            .abs()\n",
    "            .unitScale(min(VH_percabs),max(VH_percabs))\n",
    "            .multiply(255)\n",
    "            .toByte()\n",
    "            .glcmTexture(size = 3)\n",
    "            .select(['VV_gs_ent','VV_gs_diss','VV_gs_asm']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAozXa-LjM7c",
    "tags": []
   },
   "source": [
    "<span style=\"color:red\">  Sentinel 2: data pre-processing and spectral indices </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yGR4yggdjM7d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter by date\n",
    "s2filt = (s2.filterDate(\"2020-01-01\",\"2020-12-31\")\n",
    "         # filter by cloudy pixel percentage\n",
    "          .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 70))\n",
    "         .map(maskCloudAndShadowsSR)\n",
    "          # add NDVI\n",
    "         .map(lambda image: image.addBands(image.normalizedDifference(['B8', 'B4']).rename('ndvi')))\n",
    "          # add NDWI\n",
    "         .map(lambda image: image.addBands(image.normalizedDifference(['B8', 'B11']).rename('ndwi')))\n",
    "          # add GNDVI\n",
    "         .map(lambda image: image.addBands(image.normalizedDifference(['B8', 'B3']).rename('gndvi')))\n",
    "          # add  modified soil-adjusted index\n",
    "          .map(lambda image:  image.addBands(image.expression('(2 * NIR + 1 - sqrt(pow((2 * NIR + 1), 2) - 8 * (NIR - RED)) ) / 2',\n",
    "                                                       {'NIR': image\n",
    "                                                        .select('B8')\n",
    "                                                        .divide(10000),'RED': image.select('B4')\n",
    "                                                        .divide(10000)})\n",
    "                                                        .rename('msavi')))\n",
    "          # // Normalized Difference Red Edge Index\n",
    "          .map(lambda image: image.addBands(image.normalizedDifference(['B8', 'B5']).rename('ndre'))))\n",
    "\n",
    "# sdNDVI\n",
    "sdNDVI = (s2filt.select('ndvi').reduce(ee.Reducer.stdDev())\n",
    "          .rename('ndvi_std')\n",
    "          .updateMask(tcovernoloss.gt(0)))\n",
    "\n",
    "# combine spectral indices together\n",
    "spindices = (s2filt.qualityMosaic('ndvi')\n",
    "            .select('ndvi','gndvi','msavi','ndre') # quality mosaic based on ndvi and selection of indices based on max ndvi\n",
    "            .addBands(s2filt.qualityMosaic('ndwi').select('ndwi'))  # quality mosaic based on ndwi and selection of indices based on max ndwi\n",
    "            .updateMask(tcovernoloss.gt(0))) # mask only for forested areas which have been stable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7xit-FejM7d",
    "tags": []
   },
   "source": [
    "<span style=\"color:red\">  Sentinel 2 average value for each spectral index around a 3 x 3 neighbourhood </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OH7DoIA2jM7d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdNDVI_mean = sdNDVI.reduceNeighborhood(reducer = ee.Reducer.mean(),\n",
    "                             kernel = ee.Kernel.square(3))\n",
    "\n",
    "spindices_mean = spindices.reduceNeighborhood(reducer = ee.Reducer.mean(),\n",
    "                             kernel = ee.Kernel.square(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_oK2v8fjM7d",
    "tags": []
   },
   "source": [
    "<span style=\"color:red\">  Sentinel 2 texture metrics (angular second moment, entropy and dissimilarity) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSb-mCR9jM7e",
    "tags": []
   },
   "source": [
    "##### A note on the texture metrics: the data need to be rescaled between 0 and 1. We only retained pixels where both the value of the NDVI and a given spectral index are > 0 The rationale behind this choice is that any pixel with values < 0 is likely to contain things different from vegetation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NplBYfJ2jM7e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for the NDVI it is not necessary to use the percentiles\n",
    "ndvi_text = (spindices.select('ndvi')\n",
    "                     .updateMask(spindices.select('ndvi').gt(0))\n",
    "                     # convert to byte (needed for texture calculation)\n",
    "                     .multiply(255)\n",
    "                     .toByte()\n",
    "                      # calculate texture metrics\n",
    "                     .glcmTexture(size = 3)\n",
    "                     .select('ndvi_asm','ndvi_ent','ndvi_diss'))\n",
    "\n",
    "# green chlorophyll index\n",
    "gndvi_text = (spindices.updateMask(spindices.select('ndvi').gt(0))\n",
    "                     .select('gndvi')\n",
    "                     # mask out values that are below the 1st and above the 99th percentiles\n",
    "                     .updateMask(spindices.select('gndvi').gt(gndviperc.get('gndvi_p1')))\n",
    "                     .updateMask(spindices.select('gndvi').lt(gndviperc.get('gndvi_p99')))\n",
    "                     # normalise between 0 and 1\n",
    "                     .unitScale(gndviperc.get('gndvi_p1'),gndviperc.get('gndvi_p99'))\n",
    "                     # convert to byte (needed for texture calculation)\n",
    "                     .multiply(255)\n",
    "                     .toByte()\n",
    "                      # calculate texture metrics\n",
    "                     .glcmTexture(size = 3)\n",
    "                     .select('gndvi_asm','gndvi_ent','gndvi_diss'))\n",
    "\n",
    "# modified soil-adjusted index\n",
    "msavi_text = (spindices.updateMask(spindices.select('ndvi').gt(0))\n",
    "                     .select('msavi')\n",
    "                     # mask out values that are below the 1st and above the 99th percentiles\n",
    "                     .updateMask(spindices.select('msavi').gt(msaviperc.get('msavi_p1')))\n",
    "                     .updateMask(spindices.select('msavi').lt(msaviperc.get('msavi_p99')))\n",
    "                     # normalise between 0 and 1\n",
    "                     .unitScale(msaviperc.get('msavi_p1'),msaviperc.get('msavi_p99'))\n",
    "                     # convert to byte (needed for texture calculation)\n",
    "                     .multiply(255)\n",
    "                     .toByte()\n",
    "                      # calculate texture metrics\n",
    "                     .glcmTexture(size = 3)\n",
    "                     .select('msavi_asm','msavi_ent','msavi_diss'))\n",
    "\n",
    "# red-edge chlorophyll index\n",
    "ndre_text = (spindices.updateMask(spindices.select('ndvi').gt(0))\n",
    "                     .select('ndre')\n",
    "                     # mask out values that are below the 1st and above the 99th percentiles\n",
    "                     .updateMask(spindices.select('ndre').gt(ndreperc.get('ndre_p1')))\n",
    "                     .updateMask(spindices.select('ndre').lt(ndreperc.get('ndre_p99')))\n",
    "                     # normalise between 0 and 1\n",
    "                     .unitScale(ndreperc.get('ndre_p1'),ndreperc.get('ndre_p99'))\n",
    "                     # convert to byte (needed for texture calculation)\n",
    "                     .multiply(255)\n",
    "                     .toByte()\n",
    "                      # calculate texture metrics\n",
    "                     .glcmTexture(size = 3)\n",
    "                     .select('ndre_asm','ndre_ent','ndre_diss'))\n",
    "\n",
    "# normalised difference water index\n",
    "ndwi_text = (spindices.updateMask(spindices.select('ndvi').gt(0))\n",
    "                     .select('ndwi')\n",
    "                     # mask out values that are below the 1st and above the 99th percentiles\n",
    "                     .updateMask(spindices.select('ndwi').gt(ndwiperc.get('ndwi_p1')))\n",
    "                     .updateMask(spindices.select('ndwi').lt(ndwiperc.get('ndwi_p99')))\n",
    "                     # normalise between 0 and 1\n",
    "                     .unitScale(ndwiperc.get('ndwi_p1'),ndwiperc.get('ndwi_p99'))\n",
    "                     # convert to byte (needed for texture calculation)\n",
    "                     .multiply(255)\n",
    "                     .toByte()\n",
    "                      # calculate texture metrics\n",
    "                     .glcmTexture(size = 3)\n",
    "                     .select('ndwi_asm','ndwi_ent','ndwi_diss'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7doyqnr-jM7e",
    "tags": []
   },
   "source": [
    "<span style=\"color:red\">  Alos palsar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocwvRGUvjM7e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DNhh = alos.select('HH').mean().pow(2).log10().multiply(10).subtract(83)#.first() #// γ₀ = 10log₁₀(DN²) - 83.0 dB\n",
    "DNhv = alos.select('HV').mean().pow(2).log10().multiply(10).subtract(83)#.mean() #// γ₀ = 10log₁₀(DN²) - 83.0 dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHusgGNqn1Wt"
   },
   "outputs": [],
   "source": [
    "alos_mean = (DNhh.rename('alos_HH')\n",
    "    .addBands(DNhv.rename('alos_HV'))\n",
    "    .updateMask(tcovernoloss.gt(0))\n",
    "    .reduceNeighborhood(reducer = ee.Reducer.mean(),\n",
    "                             kernel = ee.Kernel.square(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcb0YxHSjM7f",
    "tags": []
   },
   "source": [
    "<span style=\"color:red\">  Alos palsar data texture metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9w6wYsyRjM7f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Global\n",
    "hhperc = {'hh_p1':4.634242727191889, 'hh_p99':18.870941152756455}\n",
    "hvperc = {'hv_p1':10.135550169048622, 'hv_p99':29.87896390839444}\n",
    "\n",
    "alos_hh_text = (DNhh.updateMask(tcovernoloss.gt(0))\n",
    "                     .abs()\n",
    "                     # normalise between 0 and 1\n",
    "                     .unitScale(hhperc.get('hh_p1'),hhperc.get('hh_p99'))\n",
    "                     # convert to byte (needed for texture calculation)\n",
    "                     .multiply(255)\n",
    "                     .toByte()\n",
    "                      # calculate texture metrics\n",
    "                     .glcmTexture(size = 3)\n",
    "                     .select('HH_asm','HH_ent','HH_diss'))\n",
    "\n",
    "\n",
    "alos_hv_text = (DNhv.updateMask(tcovernoloss.gt(0))\n",
    "                     .abs()\n",
    "                     # normalise between 0 and 1\n",
    "                     .unitScale(hhperc.get('hh_p1'),hhperc.get('hh_p99'))\n",
    "                     # convert to byte (needed for texture calculation)\n",
    "                     .multiply(255)\n",
    "                     .toByte()\n",
    "                      # calculate texture metrics\n",
    "                     .glcmTexture(size = 3)\n",
    "                     .select('HV_asm','HV_ent','HV_diss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6IUAwjaHjM7f",
    "tags": []
   },
   "source": [
    "<span style=\"color:red\"> Sentinel 1 -based coherence data </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzczjLRcjM7f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6-day coherence data for the summer\n",
    "summer_VV06_data = (ee.Image(\"users/marcogirardello/forbiores/coherence/summer_vv_COH06_100\")\n",
    "                            .updateMask(tcovernoloss.gt(0))).rename(['coh_6day_summer'])\n",
    "\n",
    "# 12-day coherence data for the summer\n",
    "summer_VV12_data = (ee.Image(\"users/marcogirardello/forbiores/coherence/summer_vv_COH12_100\")\n",
    "                            .updateMask(tcovernoloss.gt(0))).rename(['coh_12day_summer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agKn0_bvNbG6"
   },
   "outputs": [],
   "source": [
    "############## Warning - mask GEDI shots - we reduce the size of the data\n",
    "tcovernoloss = tcovernoloss.updateMask(strmetrs.select('rh50').gt(0))\n",
    "####gedi_mask = strmetrs.select('rh50').updateMask(strmetrs.select('rh50').gt(0))\n",
    "\n",
    "strmetrs = strmetrs.multiply(10000)\n",
    "S1gs_mean = S1gs_mean.multiply(10000)\n",
    "S1_VV_std_mean = S1_VV_std_mean.multiply(10000)\n",
    "S1_VH_std_mean = S1_VH_std_mean.multiply(10000)\n",
    "VV_bimon_mean = VV_bimon_mean.multiply(10000)\n",
    "VH_bimon_mean = VH_bimon_mean.multiply(10000)\n",
    "glcmVHG = glcmVHG.multiply(10000)\n",
    "glcmVVG = glcmVVG.multiply(10000)\n",
    "spindices_mean = spindices_mean.multiply(10000)\n",
    "sdNDVI_mean = sdNDVI_mean.multiply(10000)\n",
    "ndvi_text = ndvi_text.multiply(10000)\n",
    "gndvitext = gndvi_text.multiply(10000)\n",
    "msavi_text = msavi_text.multiply(10000)\n",
    "ndre_text = ndre_text.multiply(10000)\n",
    "ndwi_text = ndwi_text.multiply(10000)\n",
    "alos_mean = alos_mean.multiply(10000)\n",
    "alos_hh_text = alos_hh_text.multiply(10000)\n",
    "alos_hv_text = alos_hv_text.multiply(10000)\n",
    "aspect = aspect.multiply(10000)\n",
    "slope = slope.multiply(10000)\n",
    "fcover = fcover.multiply(10000)\n",
    "TCD = TCD.multiply(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2HpIyQLjM7g"
   },
   "source": [
    "<span style=\"color:red\">  Put everything together </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98t055v9jM7g"
   },
   "outputs": [],
   "source": [
    "trainingdat = (strmetrs.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()\n",
    "               .addBands(S1gs_mean.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # S1 mean backscatter data for growing season\n",
    "               .addBands(S1_VV_std_mean.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # S1 temporal variability backscatter data for growing season VV polarisation\n",
    "               .addBands(S1_VH_std_mean.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # S1 temporal variability backscatter data for growing season VH polarisation\n",
    "               .addBands(VV_bimon_mean.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # S1 bimonthly composites VV polarisation\n",
    "               .addBands(VH_bimon_mean.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # S1 bimonthly composites VH polarisation\n",
    "               .addBands(glcmVHG.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # S1 texture metrics VH polarisation\n",
    "               .addBands(glcmVVG.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # S1 texture metrics VV polarisation\n",
    "               .addBands(spindices_mean.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # S2 mean values of spectral indices\n",
    "               .addBands(sdNDVI_mean.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # S2 mean values of spectral indices\n",
    "               .addBands(ndvi_text.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # ndvi texture metrics\n",
    "               .addBands(gndvi_text.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # gndvi texture metrics\n",
    "               .addBands(msavi_text.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # msavi texture metrics\n",
    "               .addBands(ndre_text.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # rcl texture metrics\n",
    "               .addBands(ndwi_text.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # ndwi texture metrics\n",
    "               .addBands(summer_VV06_data.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # coherence summer data 6 days\n",
    "               .addBands(summer_VV12_data.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # coherence summer data 12 days\n",
    "               .addBands(alos_mean.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # alos palsar mean\n",
    "               .addBands(alos_hh_text.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # alos palsar texture HH\n",
    "               .addBands(alos_hv_text.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # alos palsar texture HV\n",
    "               .addBands(elevation.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # elevation\n",
    "               .addBands(slope.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # slope\n",
    "               .addBands(aspect.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # aspect\n",
    "               .addBands(biomass.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # biomass Santoro (AGB 2018 v3)\n",
    "               .addBands(fcover.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # fcover Copernicus\n",
    "               .addBands(TCD.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # Tree cover density Copernicus\n",
    "               .addBands(soil.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # soil\n",
    "               .addBands(temperature.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # temperature\n",
    "               .addBands(precipitation.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # precipitation\n",
    "               .addBands(ET.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # The Potential Evapo-Transpiration (ET0) Database v3\n",
    "               .addBands(ETsd.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # The Potential Evapo-Transpiration (ET0) std Database v3\n",
    "               .addBands(aridity.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # Global Aridity Index (Global-AI) Database v3\n",
    "               .addBands(grid1km.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # 1 km grid\n",
    "               .addBands(grid5km.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # 5 km grid\n",
    "               .addBands(grid10km.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # 10 km grid\n",
    "               .addBands(grid20km.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # 20 km grid\n",
    "               .addBands(grid30km.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # 30 km grid\n",
    "               .addBands(grid40km.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32()) # 40 km grid\n",
    "               .addBands(grid50km.updateMask(tcovernoloss.gt(0)).unmask(-2147483648).toInt32())) # 50 km grid\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "14Hr6m3U2evN2TPg1QqeWO9440aud1gEO",
     "timestamp": 1715203167443
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
